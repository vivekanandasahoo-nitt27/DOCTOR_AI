# ğŸ©º Doctor AI â€“ Multimodal Medical Assistant

## ğŸ“Œ Overview
Doctor AI is a **multimodal medical assistant** designed to simulate a real-world doctorâ€“patient interaction.  
The system accepts **voice, image, and text inputs**, performs medical reasoning using **Groq LLMs**, supports **follow-up chatbot conversations**, generates a **final medical report (PDF with signature)**, and provides **spoken responses** using text-to-speech.

The application is **containerized, deployed on AWS EC2**, and uses a **CI/CD pipeline with GitHub Actions and Amazon ECR**.

âš ï¸ This project is built for **learning and demonstration purposes only** and does **not replace a licensed medical professional**.

---

## ğŸš€ Key Features

- ğŸ™ï¸ **Voice Input** (Speech-to-Text using Groq Whisper)
- ğŸ–¼ï¸ **Medical Image Analysis** (Vision-capable Groq LLM)
- ğŸ’¬ **Follow-up Medical Chatbot**
- ğŸ§  **LLM-based Medical Reasoning (Doctor Brain)**
- ğŸ§¾ **Final Medical Report Generation (PDF)**
  - Medical observations
  - Medication suggestions
  - Handwritten-style formatting
  - Doctor signature
- ğŸ”Š **Natural Voice Output** (ElevenLabs Text-to-Speech)
- ğŸ–¥ï¸ **Interactive Frontend** using Gradio
- ğŸ³ **Dockerized Application**
- â˜ï¸ **AWS Deployment (EC2 + ECR)**
- ğŸ” **CI/CD Pipeline using GitHub Actions**

---

## ğŸ§  System Architecture

Patient (Voice / Image / Text)
â†“
Speech â†’ Groq Whisper
Image â†’ Vision LLM (Groq)
â†“
Dynamic Prompt Construction
â†“
Doctor Brain (Groq LLM)
â†“
Initial Medical Response
â†“
Follow-up Chatbot
â†“
Structured Medical Report (PDF)
â†“
Voice Output (ElevenLabs)
â†“
Gradio Frontend (AWS EC2)


---

## ğŸ› ï¸ Tech Stack

- **LLMs:** Groq (LLaMA-based models)
- **Speech-to-Text:** Groq Whisper
- **Text-to-Speech:** ElevenLabs
- **LLM Orchestration:** LangChain
- **Frontend:** Gradio
- **Backend:** Python
- **PDF Generation:** ReportLab
- **Containerization:** Docker
- **CI/CD:** GitHub Actions
- **Cloud:** AWS EC2, Amazon ECR, IAM

---

## â˜ï¸ AWS Deployment & CI/CD Pipeline

### ğŸ”¹ Deployment Strategy
- The application is **containerized using Docker**
- Docker images are stored in **Amazon Elastic Container Registry (ECR)**
- The container runs on an **AWS EC2 instance**

### ğŸ”¹ CI/CD with GitHub Actions
A CI/CD pipeline is configured to automate deployment:

1. Code is pushed to GitHub
2. GitHub Actions workflow is triggered
3. Docker image is built
4. Image is pushed to **Amazon ECR**
5. EC2 instance pulls the latest image from ECR
6. Container is restarted with the updated version

### ğŸ”¹ Security
- **IAM roles and policies** are used for secure access
- No AWS credentials are hardcoded
- Secrets are managed using **GitHub Secrets** and **EC2 environment variables**

ğŸ“Œ **Why this approach?**
> This ensures reproducible builds, faster deployments, and production-ready ML system practices.

---

## ğŸ“‚ Project Structure

â”œâ”€â”€ app.py # Main Gradio application
â”œâ”€â”€ brain_of_the_doctor.py # Image analysis & medical reasoning
â”œâ”€â”€ voice_of_the_patient.py # Speech-to-text using Groq Whisper
â”œâ”€â”€ voice_of_the_doctor.py # Text-to-speech using ElevenLabs
â”œâ”€â”€ disease_chat.py # Follow-up medical chatbot
â”œâ”€â”€ doctor_report.py # Medical report (PDF) generation
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .github/workflows/ # GitHub Actions CI/CD pipeline
â”œâ”€â”€ assets/
â”‚ â””â”€â”€ signature.jpeg
â”œâ”€â”€ fonts/
â”‚ â””â”€â”€ DoctorHandwriting.ttf
â””â”€â”€ requirements.txt


---

## ğŸ”„ Application Flow

1. Patient provides **voice, image, or text**
2. Voice is transcribed using **Groq Whisper**
3. Image is analyzed using a **vision-enabled LLM**
4. Inputs are merged into a **dynamic medical prompt**
5. Doctor Brain LLM generates a medical response
6. User interacts via **chatbot for follow-ups**
7. A **final signed medical report (PDF)** is generated
8. Doctor response is converted to **speech**
9. Output is served via **Gradio on AWS EC2**

---

## ğŸ“Š Why Multimodal AI?

Medical consultations are inherently multimodal:
- Patients **speak** symptoms
- **Show visual signs**
- Ask **follow-up questions**

Doctor AI mirrors real clinical interaction using AI.

---

## âš ï¸ Limitations & Disclaimer

- â— Not a real diagnostic system
- â— Depends on input quality
- â— No real-time vitals or lab integration
- â— Always advises consulting a licensed doctor

> This project is for **educational and research purposes only**.

---

## ğŸŒ± Future Improvements

- Retrieval-Augmented Generation (RAG) with verified medical sources
- Multilingual speech support
- Wearable device integration
- Doctor-in-the-loop validation
- Scalable production frontend

---

## ğŸ‘¨â€ğŸ’» Creator

**Vivekananda Sahoo**  
Machine Learning | Generative AI | MLOps Enthusiast  

---

## â­ Acknowledgements

- Groq for low-latency LLM inference
- ElevenLabs for natural voice synthesis
- Gradio for rapid AI UI development
- AWS for cloud infrastructure

---

## ğŸ“œ License

This project is released for **learning and demonstration purposes only**.